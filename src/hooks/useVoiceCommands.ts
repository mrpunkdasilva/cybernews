'use client';

import { useState, useEffect, useCallback } from 'react';
import { voiceCommandProcessor } from '@/services/voice/VoiceCommandProcessor';

interface VoiceCommandsConfig {
  lang: string;
}

export function useVoiceCommands({ lang }: VoiceCommandsConfig) {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);

  const startListening = useCallback(() => {
    if (!('webkitSpeechRecognition' in window)) {
      setError('Speech recognition not supported');
      return;
    }

    const recognition = new (window as any).webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = lang; // Pode ser configurÃ¡vel

    recognition.onstart = () => {
      setIsListening(true);
      setError(null);
    };

    recognition.onresult = (event: any) => {
      const current = event.resultIndex;
      const transcript = event.results[current][0].transcript;
      setTranscript(transcript);
      
      voiceCommandProcessor.processCommand(transcript).then(wasProcessed => {
        if (!wasProcessed) {
          console.log('No command matched:', transcript);
        }
      });
    };

    recognition.onerror = (event: any) => {
      setError(event.error);
      setIsListening(false);
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    recognition.start();
  }, []);

  const stopListening = useCallback(() => {
    setIsListening(false);
  }, []);

  return {
    isListening,
    transcript,
    error,
    startListening,
    stopListening,
    availableCommands: voiceCommandProcessor.getAvailableCommands()
  };
}